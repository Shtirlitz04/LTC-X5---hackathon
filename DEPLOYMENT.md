# Инструкция по развертыванию и запуску сервиса

В этом документе приведена пошаговая инструкция по установке зависимостей и запуску веб-сервиса на локальной машине или сервере.

## 1. Технические требования

### 1.1. Программное обеспечение
*   **Python**: Версия 3.8 или выше.
*   **Pip**: Менеджер пакетов для Python.
*   **Git**: Для клонирования репозитория.

### 1.2. Аппаратные требования
*   **CPU**: Сервис может работать на CPU, однако для выполнения требования по времени отклика (< 1 секунды) под высокой нагрузкой **настоятельно рекомендуется использовать GPU**.
*   **GPU**: Любая NVIDIA GPU с поддержкой **CUDA** (версия 11.x или выше).
*   **Оперативная память (RAM)**: Минимум 8 ГБ, рекомендуется 16 ГБ+.

## 2. Установка и подготовка

### Шаг 1: Клонирование репозитория
Откройте терминал и выполните следующую команду:

```bash
git clone <URL-вашего-репозитория>
cd project-ner
```

### Шаг 2: Установка зависимостей
Рекомендуется использовать виртуальное окружение, чтобы изолировать зависимости проекта.

1.  **Создайте и активируйте виртуальное окружение:**
    ```bash
    # Создаем окружение
    python -m venv venv

    # Активируем его
    # Для Linux / macOS:
    source venv/bin/activate
    # Для Windows:
    # venv\Scripts\activate
    ```

2.  **Установите все необходимые библиотеки из файла `requirements.txt`:**
    ```bash
    pip install -r requirements.txt
    ```

### Шаг 3: Размещение модели
Для работы сервиса необходимы файлы предобученной модели.

1.  Скачайте или скопируйте артефакты вашей обученной модели (файлы `config.json`, `pytorch_model.bin`, `tokenizer_config.json` и др.).
2.  Поместите их в директорию `models/rubert_ner_v1/`.

> **Важно:** Убедитесь, что путь к модели, указанный в файле `server/model.py` в переменной `MODEL_PATH`, соответствует этому расположению.

## 3. Запуск веб-сервиса

### 3.1. Локальный запуск для разработки
Этот режим удобен для отладки, так как сервер автоматически перезапускается при изменении кода.

Выполните команду из корневой директории проекта:
```bash
uvicorn server.main:app --host 0.0.0.0 --port 8000 --reload
```
*   Сервис будет доступен по адресу `http://localhost:8000`.
*   Интерактивная документация API (Swagger UI) будет доступна по адресу `http://localhost:8000/docs`.

### 3.2. Запуск в "продакшн" режиме
Для развертывания на сервере используйте запуск с несколькими рабочими процессами (workers) для стабильности и производительности.

```bash
# Пример запуска с 4-мя рабочими процессами
uvicorn server.main:app --host 0.0.0.0 --port 8000 --workers 4
```

## 4. Проверка работоспособности
После запуска сервера вы можете проверить его работу, отправив `POST` запрос на эндпоинт `/api/predict`.

**Пример запроса с помощью `curl`:**
```bash
curl -X 'POST' \
  'http://localhost:8000/api/predict' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "input": "чипсы лейс 200г"
}'
```

**Ожидаемый ответ:**
```json
[
  {
    "start_index": 0,
    "end_index": 5,
    "entity": "B-TYPE"
  },
  {
    "start_index": 6,
    "end_index": 10,
    "entity": "B-BRAND"
  },
  {
    "start_index": 11,
    "end_index": 15,
    "entity": "B-VOLUME"
  }
]
```
Успешное получение ответа в указанном формате означает, что сервис развернут и работает корректно.
