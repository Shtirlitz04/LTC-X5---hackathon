```text
project-ner/
│
├── data/
│   ├── raw/
│   │   ├── train.csv
│   │   ├── submission.csv
│   │   └── close_submission.csv
│   └── processed/
│
├── docs/
│   └── ТЗ.pdf             # Техническое задание
│
├── models/
│   └── rubert_ner_v1/
│
├── notebooks/
│   └── rubert.ipynb
├── docker/
│   └── readme.md
│
├── server/
│   ├── api/
│   │   ├── routes.py
│   │   └── __init__.py
│   ├── static/
│   │   └── index.html
│   ├── __init__.py
│   ├── main.py             # Основной файл для запуска сервера
│   ├── lifespan.py         # Управление жизненным циклом (загрузка модели)
│   ├── batcher.py          # Пакетная обработка запросов
│   └── schemas.py          # Схемы данных Pydantic для API
│
├── src/
│   ├── __init__.py
│   ├── config.py
│   ├── dataset.py
│   ├── model.py
│   └── train.py            # Код для ОБУЧЕНИЯ модели
│   
├── .gitignore
└── requirements.txt
```


# Cервис выделения сущностей (NER) для X5

Этот репозиторий содержит решение для задачи №10 хакатона «Лидеры цифровой трансформации» — **"Сервис выделения сущностей из поискового запроса клиента в мобильном приложении торговой сети «Пятерочка»"**.

## 1. Описание задачи и целевые сущности

### 1.1. Контекст задачи
Разрабатываемый сервис предназначен для **выделения именованных сущностей (NER)** из поисковых запросов клиентов. Цель — сделать поиск «умнее», научив систему понимать не просто ключевые слова, а контекст запроса: бренд, категорию товара, объем и т.д.

### 1.2. Целевые сущности
Сервис распознает четыре типа сущностей в формате **BIO-разметки** (`B-ENTITY`, `I-ENTITY`, `O`):

| Сущность | Описание | Пример |
| :--- | :--- | :--- |
| `TYPE` | Категория товара | *молоко, хлеб, чипсы* |
| `BRAND` | Бренд | *Соса-Cola, Простоквашино* |
| `VOLUME` | Объём/вес/количество | *0.5 л, 200 г, 10 шт.* |
| `PERCENT` | Процент | *2.5%, 15%* |

### 1.3. Ключевые требования к сервису
Архитектура сервиса спроектирована с учетом ключевых требований из технического задания:
*   **Время отклика:** Не более **1 секунды** на запрос.
*   **Endpoint:** Реализован эндпоинт `POST /api/predict`.
*   **Доступность:** Сервис доступен по публичному URL **без авторизации**.
*   **Формат ответа:** Строго соответствует формату, указанному в ТЗ:
    ```json
    [
      {"start_index": 0, "end_index": 8, "entity": "B-TYPE"},
      {"start_index": 9, "end_index": 15, "entity": "I-TYPE"}
    ]
    ```

## 2. Архитектура сервиса и оптимизация производительности

Сервис построен на базе асинхронного веб-фреймворка **FastAPI** с использованием **PyTorch** и **Hugging Face Transformers**.

### 2.1. Динамический батчинг (Ключ к 1-секундному отклику)

Для выполнения критического требования по времени отклика и обеспечения масштабируемости, сервис использует механизм **динамического батчинга**.

| Компонент | Назначение |
| :--- | :--- |
| `server/batcher.py` | Класс `DynamicBatcher`, работающий в фоновом режиме. Асинхронно собирает входящие запросы в батчи и отправляет их на обработку одним вызовом, что **драматически повышает эффективность использования GPU/CPU**. |
| `server/lifespan.py` | **Критический компонент**. Запускает батчер при старте сервера и передает ему функцию предсказания `_predict_batch` из `model.py`. Настройки батчера (`batch_size=8`, `max_wait=0.05` сек) позволяют минимизировать задержку. |

### 2.2. Модуль работы с моделью (`server/model.py`)

Этот модуль инкапсулирует всю логику, связанную с загрузкой и использованием нейросетевой модели.
*   **Загрузка**: Модель `BERT` и токенизатор загружаются из директории `./models/` **один раз** при старте сервера.
*   **Оптимизация**: Модель автоматически переводится в режим `eval()` и перемещается на `cuda` (если доступен).
*   **Обработка данных**: Функция `_predict_batch` принимает батч текстов и выполняет:
    1.  Токенизацию, паддинг и преобразование в тензоры.
    2.  Предсказание в режиме `torch.no_grad()` для экономии памяти.
    3.  **Постобработку**: декодирование меток с корректным **объединением subword-токенов** для точного определения границ сущностей.

### 2.3. Внешние источники и предобученные модели

*   **Предобученная модель**: Для решения задачи используется готовая предобученная языковая модель на архитектуре **BERT** (например, `sberbank-ai/ruBERT-base`), дообученная на предоставленных данных.
*   **Библиотеки**: Для работы с данными и ML-моделью используются рекомендованные ТЗ библиотеки: **Python, PyTorch, Hugging Face Transformers, FastAPI**.
*   **Использованные данные**:
    *   **Обучающая выборка**: `data/raw/train.csv`.
    *   **Тестовые выборки**: `data/raw/submission.csv` и `data/raw/close_submission.csv`.
*   **Запрещенные источники**: В соответствии с ТЗ, **не** использовались ручные словари, готовые коммерческие NER-API или любые закрытые/приватные датасеты.

## 3. Технические требования и развертывание

#### *Имеется отдельная возможность запуска решения через [docker-image](./docker/)*

### 3.1. Установка зависимостей

Для работы сервиса необходим Python 3.8+ и зависимости, перечисленные в файле `requirements.txt`.

1.  Клонируйте репозиторий:
    ```bash
    git clone <URL-вашего-репозитория>
    cd project-ner
    ```
2.  Создайте и активируйте виртуальное окружение (рекомендуется):
    ```bash
    python -m venv venv
    source venv/bin/activate  # Для Windows: venv\Scripts\activate
    ```
3.  Установите все необходимые библиотеки:
    ```bash
    pip install -r requirements.txt
    ```

### 3.2. Запуск веб-сервиса

Перед запуском убедитесь, что обученная модель находится в директории `models/rubert_ner_v1/`.

Для запуска веб-сервиса на локальной машине выполните команду из корневой директории проекта:
```bash
uvicorn server.main:app --host 0.0.0.0 --port 8000
```
*   Сервис будет доступен по адресу `http://localhost:8000`.
*   Интерактивная документация API (Swagger UI) будет доступна по адресу `http://localhost:8000/docs`.

### 3.3. Пример запроса к API

Вы можете отправить `POST` запрос на эндпоинт `/api/predict` с помощью `curl` или любого другого API-клиента.

**Пример с использованием `curl`:**
```bash
curl -X 'POST' \
  'http://localhost:8000/api/predict' \
  -H 'Content-Type: application/json' \
  -d '{
  "input": "молоко простоквашино 3.2% 1л"
}'
```

**Ожидаемый ответ:**
```json
[
    {
        "start_index": 0,
        "end_index": 6,
        "entity": "B-TYPE"
    },
    {
        "start_index": 7,
        "end_index": 20,
        "entity": "B-BRAND"
    },
    {
        "start_index": 21,
        "end_index": 25,
        "entity": "B-PERCENT"
    },
    {
        "start_index": 26,
        "end_index": 28,
        "entity": "B-VOLUME"
    }
]
```
